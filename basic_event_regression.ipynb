{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from eventcnn.datasources.davis import DavisDataset\n",
    "from eventcnn.datasources.eventsource import EventSource, CachedDenseEventSource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "source = CachedDenseEventSource(\"data/dense\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N_EVENT_SLICES = source.event_slices\n",
    "BATCH_SIZE = 8\n",
    "N_EVENT_ROWS = source.rows\n",
    "N_EVENT_COLS = source.cols\n",
    "LABEL_SCALE_FACTOR = np.float32(1.0 / np.max(np.abs(source.training()[\"labels\"])))  # Rescale the positions to be in the range [-1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Copied from the tensorflow tutorial in class\n",
    "def init_weights(shape):\n",
    "    return tf.Variable(tf.random_normal(shape, stddev=0.01))\n",
    "\n",
    "def init_bias(shape):\n",
    "    return tf.Variable(tf.zeros(shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def n_output_channels(layer):\n",
    "    return layer.get_shape()[-1].value\n",
    "\n",
    "def n_outputs(layer):\n",
    "    out = layer.get_shape()[1].value\n",
    "    for d in layer.get_shape()[2:]:\n",
    "        out *= d.value\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_tensor = tf.placeholder(tf.float32, [None, \n",
    "                                           N_EVENT_COLS, \n",
    "                                           N_EVENT_ROWS, \n",
    "                                           N_EVENT_SLICES, \n",
    "                                           2])\n",
    "dropout_keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "conv1 = tf.nn.conv3d(input_tensor, init_weights([3,3,3,2,6]), \n",
    "                     strides=[1,1,1,1,1], padding='SAME')\n",
    "conv1 = tf.nn.relu(tf.nn.bias_add(conv1, init_bias(n_output_channels(conv1))))\n",
    "pool1 = tf.nn.max_pool3d(conv1, ksize=[1, 2, 2, 2, 1], \n",
    "                         strides=[1, 2, 2, 2, 1], padding=\"SAME\")\n",
    "\n",
    "conv2 = tf.nn.conv3d(pool1, \n",
    "                     init_weights([3,3,2, n_output_channels(pool1),6]), \n",
    "                     strides=[1, 1, 1, 1, 1], padding=\"SAME\")\n",
    "conv2 = tf.nn.relu(tf.nn.bias_add(conv2, init_bias(n_output_channels(conv2))))\n",
    "pool2 = tf.nn.max_pool3d(conv1, ksize=[1, 2, 2, 2, 1], strides=[1, 2, 2, 2, 1], padding=\"SAME\")\n",
    "\n",
    "fc3 = tf.reshape(pool2, [-1, n_outputs(pool2)])\n",
    "fc3 = tf.add(tf.matmul(fc3, init_weights([n_outputs(pool2), 32])), init_bias(32))\n",
    "fc3 = tf.nn.relu(fc3)\n",
    "fc3 = tf.nn.dropout(fc3, dropout_keep_prob)\n",
    "\n",
    "out = tf.add(tf.matmul(fc3, init_weights([n_outputs(fc3), 3])), init_bias(3))\n",
    "\n",
    "y = tf.placeholder(tf.float32, [None, 3])\n",
    "\n",
    "loss = tf.nn.l2_loss(tf.sub(out, tf.mul(LABEL_SCALE_FACTOR, y)))\n",
    "avg_loss = tf.reduce_mean(loss)\n",
    "train_optimizer = tf.train.AdamOptimizer(learning_rate=0.001).minimize(loss)\n",
    "\n",
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "0 8\n",
      "0 16\n",
      "0 24\n",
      "0 32\n",
      "0 40\n",
      "0 48\n",
      "0 56\n",
      "0 64\n",
      "0 72\n",
      "0 80\n",
      "0 88\n",
      "0 96\n",
      "0 104\n",
      "0 112\n",
      "0 120\n",
      "0 128\n",
      "0 136\n",
      "0 144\n",
      "0 152\n",
      "0 160\n",
      "0 168\n",
      "0 176\n",
      "0 184\n",
      "0 192\n",
      "0 200\n",
      "0 208\n",
      "0 216\n",
      "0 224\n",
      "0 232\n",
      "0 240\n",
      "0 248\n",
      "0 256\n",
      "0 264\n",
      "0 272\n",
      "0 280\n",
      "0 288\n",
      "0 296\n",
      "0 304\n",
      "0 312\n",
      "0 320\n",
      "0 328\n",
      "0 336\n",
      "0 344\n",
      "0 352\n",
      "0 360\n",
      "0 368\n",
      "0 376\n",
      "0 384\n",
      "0 392\n",
      "0 400\n",
      "0 408\n",
      "0 416\n",
      "0 424\n",
      "0 432\n",
      "0 440\n",
      "0 448\n",
      "0 456\n",
      "0 464\n",
      "0 472\n",
      "0 480\n",
      "0 488\n",
      "0 496\n",
      "0 504\n",
      "0 512\n",
      "0 520\n",
      "0 528\n",
      "0 536\n",
      "0 544\n",
      "0 552\n",
      "0 560\n",
      "0 568\n",
      "0 576\n",
      "0 584\n",
      "0 592\n",
      "0 600\n",
      "0 608\n",
      "0 616\n",
      "0 624\n",
      "0 632\n",
      "0 640\n",
      "0 648\n",
      "avg: 12.3849\n",
      "1 0\n",
      "1 8\n",
      "1 16\n",
      "1 24\n",
      "1 32\n",
      "1 40\n",
      "1 48\n",
      "1 56\n",
      "1 64\n",
      "1 72\n",
      "1 80\n",
      "1 88\n",
      "1 96\n",
      "1 104\n",
      "1 112\n",
      "1 120\n",
      "1 128\n",
      "1 136\n",
      "1 144\n",
      "1 152\n",
      "1 160\n",
      "1 168\n",
      "1 176\n",
      "1 184\n",
      "1 192\n",
      "1 200\n",
      "1 208\n",
      "1 216\n",
      "1 224\n",
      "1 232\n",
      "1 240\n",
      "1 248\n",
      "1 256\n",
      "1 264\n",
      "1 272\n",
      "1 280\n",
      "1 288\n",
      "1 296\n",
      "1 304\n",
      "1 312\n",
      "1 320\n",
      "1 328\n",
      "1 336\n",
      "1 344\n",
      "1 352\n",
      "1 360\n",
      "1 368\n",
      "1 376\n",
      "1 384\n",
      "1 392\n",
      "1 400\n",
      "1 408\n",
      "1 416\n",
      "1 424\n",
      "1 432\n",
      "1 440\n",
      "1 448\n",
      "1 456\n",
      "1 464\n",
      "1 472\n",
      "1 480\n",
      "1 488\n",
      "1 496\n",
      "1 504\n",
      "1 512\n",
      "1 520\n",
      "1 528\n",
      "1 536\n",
      "1 544\n",
      "1 552\n",
      "1 560\n",
      "1 568\n",
      "1 576\n",
      "1 584\n",
      "1 592\n",
      "1 600\n",
      "1 608\n",
      "1 616\n",
      "1 624\n",
      "1 632\n",
      "1 640\n",
      "1 648\n",
      "avg: 10.6835\n",
      "2 0\n",
      "2 8\n",
      "2 16\n",
      "2 24\n",
      "2 32\n",
      "2 40\n",
      "2 48\n",
      "2 56\n",
      "2 64\n",
      "2 72\n",
      "2 80\n",
      "2 88\n",
      "2 96\n",
      "2 104\n",
      "2 112\n",
      "2 120\n",
      "2 128\n",
      "2 136\n",
      "2 144\n",
      "2 152\n",
      "2 160\n",
      "2 168\n",
      "2 176\n",
      "2 184\n",
      "2 192\n",
      "2 200\n",
      "2 208\n",
      "2 216\n",
      "2 224\n",
      "2 232\n",
      "2 240\n",
      "2 248\n",
      "2 256\n",
      "2 264\n",
      "2 272\n",
      "2 280\n",
      "2 288\n",
      "2 296\n",
      "2 304\n",
      "2 312\n",
      "2 320\n",
      "2 328\n",
      "2 336\n",
      "2 344\n",
      "2 352\n",
      "2 360\n",
      "2 368\n",
      "2 376\n",
      "2 384\n",
      "2 392\n",
      "2 400\n",
      "2 408\n",
      "2 416\n",
      "2 424\n",
      "2 432\n",
      "2 440\n",
      "2 448\n",
      "2 456\n",
      "2 464\n",
      "2 472\n",
      "2 480\n",
      "2 488\n",
      "2 496\n",
      "2 504\n",
      "2 512\n",
      "2 520\n",
      "2 528\n",
      "2 536\n",
      "2 544\n",
      "2 552\n",
      "2 560\n",
      "2 568\n",
      "2 576\n",
      "2 584\n",
      "2 592\n",
      "2 600\n",
      "2 608\n",
      "2 616\n",
      "2 624\n",
      "2 632\n",
      "2 640\n",
      "2 648\n",
      "avg: 5.98306\n",
      "3 0\n",
      "3 8\n",
      "3 16\n",
      "3 24\n",
      "3 32\n",
      "3 40\n",
      "3 48\n",
      "3 56\n",
      "3 64\n",
      "3 72\n",
      "3 80\n",
      "3 88\n",
      "3 96\n",
      "3 104\n",
      "3 112\n",
      "3 120\n",
      "3 128\n",
      "3 136\n",
      "3 144\n",
      "3 152\n",
      "3 160\n",
      "3 168\n",
      "3 176\n",
      "3 184\n",
      "3 192\n",
      "3 200\n",
      "3 208\n",
      "3 216\n",
      "3 224\n",
      "3 232\n",
      "3 240\n",
      "3 248\n",
      "3 256\n",
      "3 264\n",
      "3 272\n",
      "3 280\n",
      "3 288\n",
      "3 296\n",
      "3 304\n",
      "3 312\n",
      "3 320\n",
      "3 328\n",
      "3 336\n",
      "3 344\n",
      "3 352\n",
      "3 360\n",
      "3 368\n",
      "3 376\n",
      "3 384\n",
      "3 392\n",
      "3 400\n",
      "3 408\n",
      "3 416\n",
      "3 424\n",
      "3 432\n",
      "3 440\n",
      "3 448\n",
      "3 456\n",
      "3 464\n",
      "3 472\n",
      "3 480\n",
      "3 488\n",
      "3 496\n",
      "3 504\n",
      "3 512\n",
      "3 520\n",
      "3 528\n",
      "3 536\n",
      "3 544\n",
      "3 552\n",
      "3 560\n",
      "3 568\n",
      "3 576\n",
      "3 584\n",
      "3 592\n",
      "3 600\n",
      "3 608\n",
      "3 616\n",
      "3 624\n",
      "3 632\n",
      "3 640\n",
      "3 648\n",
      "avg: 4.90385\n",
      "4 0\n",
      "4 8\n",
      "4 16\n",
      "4 24\n",
      "4 32\n",
      "4 40\n",
      "4 48\n",
      "4 56\n",
      "4 64\n",
      "4 72\n",
      "4 80\n",
      "4 88\n",
      "4 96\n",
      "4 104\n",
      "4 112\n",
      "4 120\n",
      "4 128\n",
      "4 136\n",
      "4 144\n",
      "4 152\n",
      "4 160\n",
      "4 168\n",
      "4 176\n",
      "4 184\n",
      "4 192\n",
      "4 200\n",
      "4 208\n",
      "4 216\n",
      "4 224\n",
      "4 232\n",
      "4 240\n",
      "4 248\n",
      "4 256\n",
      "4 264\n",
      "4 272\n",
      "4 280\n",
      "4 288\n",
      "4 296\n",
      "4 304\n",
      "4 312\n",
      "4 320\n",
      "4 328\n",
      "4 336\n",
      "4 344\n",
      "4 352\n",
      "4 360\n",
      "4 368\n",
      "4 376\n",
      "4 384\n",
      "4 392\n",
      "4 400\n",
      "4 408\n",
      "4 416\n",
      "4 424\n",
      "4 432\n",
      "4 440\n",
      "4 448\n",
      "4 456\n",
      "4 464\n",
      "4 472\n",
      "4 480\n",
      "4 488\n",
      "4 496\n",
      "4 504\n",
      "4 512\n",
      "4 520\n",
      "4 528\n",
      "4 536\n",
      "4 544\n",
      "4 552\n",
      "4 560\n",
      "4 568\n",
      "4 576\n",
      "4 584\n",
      "4 592\n",
      "4 600\n",
      "4 608\n",
      "4 616\n",
      "4 624\n",
      "4 632\n",
      "4 640\n",
      "4 648\n",
      "avg: 4.45562\n",
      "5 0\n",
      "5 8\n",
      "5 16\n",
      "5 24\n",
      "5 32\n",
      "5 40\n",
      "5 48\n",
      "5 56\n",
      "5 64\n",
      "5 72\n",
      "5 80\n",
      "5 88\n",
      "5 96\n",
      "5 104\n",
      "5 112\n",
      "5 120\n",
      "5 128\n",
      "5 136\n",
      "5 144\n",
      "5 152\n",
      "5 160\n",
      "5 168\n",
      "5 176\n",
      "5 184\n",
      "5 192\n",
      "5 200\n",
      "5 208\n",
      "5 216\n",
      "5 224\n",
      "5 232\n",
      "5 240\n",
      "5 248\n",
      "5 256\n",
      "5 264\n",
      "5 272\n",
      "5 280\n",
      "5 288\n",
      "5 296\n",
      "5 304\n",
      "5 312\n",
      "5 320\n",
      "5 328\n",
      "5 336\n",
      "5 344\n",
      "5 352\n",
      "5 360\n",
      "5 368\n",
      "5 376\n",
      "5 384\n",
      "5 392\n",
      "5 400\n",
      "5 408\n",
      "5 416\n",
      "5 424\n",
      "5 432\n",
      "5 440\n",
      "5 448\n",
      "5 456\n",
      "5 464\n",
      "5 472\n",
      "5 480\n",
      "5 488\n",
      "5 496\n",
      "5 504\n",
      "5 512\n",
      "5 520\n",
      "5 528\n",
      "5 536\n",
      "5 544\n",
      "5 552\n",
      "5 560\n",
      "5 568\n",
      "5 576\n",
      "5 584\n",
      "5 592\n",
      "5 600\n",
      "5 608\n",
      "5 616\n",
      "5 624\n",
      "5 632\n",
      "5 640\n",
      "5 648\n",
      "avg: 3.79267\n",
      "6 0\n",
      "6 8\n",
      "6 16\n",
      "6 24\n",
      "6 32\n",
      "6 40\n",
      "6 48\n",
      "6 56\n",
      "6 64\n",
      "6 72\n",
      "6 80\n",
      "6 88\n",
      "6 96\n",
      "6 104\n",
      "6 112\n",
      "6 120\n",
      "6 128\n",
      "6 136\n",
      "6 144\n",
      "6 152\n",
      "6 160\n",
      "6 168\n",
      "6 176\n",
      "6 184\n",
      "6 192\n",
      "6 200\n",
      "6 208\n",
      "6 216\n",
      "6 224\n",
      "6 232\n",
      "6 240\n",
      "6 248\n",
      "6 256\n",
      "6 264\n",
      "6 272\n",
      "6 280\n",
      "6 288\n",
      "6 296\n",
      "6 304\n",
      "6 312\n",
      "6 320\n",
      "6 328\n",
      "6 336\n",
      "6 344\n",
      "6 352\n",
      "6 360\n",
      "6 368\n",
      "6 376\n",
      "6 384\n",
      "6 392\n",
      "6 400\n",
      "6 408\n",
      "6 416\n",
      "6 424\n",
      "6 432\n",
      "6 440\n",
      "6 448\n",
      "6 456\n",
      "6 464\n",
      "6 472\n",
      "6 480\n",
      "6 488\n",
      "6 496\n",
      "6 504\n",
      "6 512\n",
      "6 520\n",
      "6 528\n",
      "6 536\n",
      "6 544\n",
      "6 552\n",
      "6 560\n",
      "6 568\n",
      "6 576\n",
      "6 584\n",
      "6 592\n",
      "6 600\n",
      "6 608\n",
      "6 616\n",
      "6 624\n",
      "6 632\n",
      "6 640\n",
      "6 648\n",
      "avg: 3.91245\n",
      "7 0\n",
      "7 8\n",
      "7 16\n",
      "7 24\n",
      "7 32\n",
      "7 40\n",
      "7 48\n",
      "7 56\n",
      "7 64\n",
      "7 72\n",
      "7 80\n",
      "7 88\n",
      "7 96\n",
      "7 104\n",
      "7 112\n",
      "7 120\n",
      "7 128\n",
      "7 136\n",
      "7 144\n",
      "7 152\n",
      "7 160\n",
      "7 168\n",
      "7 176\n",
      "7 184\n",
      "7 192\n",
      "7 200\n",
      "7 208\n",
      "7 216\n",
      "7 224\n",
      "7 232\n",
      "7 240\n",
      "7 248\n",
      "7 256\n",
      "7 264\n",
      "7 272\n",
      "7 280\n",
      "7 288\n",
      "7 296\n",
      "7 304\n",
      "7 312\n",
      "7 320\n",
      "7 328\n",
      "7 336\n",
      "7 344\n",
      "7 352\n",
      "7 360\n",
      "7 368\n",
      "7 376\n",
      "7 384\n",
      "7 392\n",
      "7 400\n",
      "7 408\n",
      "7 416\n",
      "7 424\n",
      "7 432\n",
      "7 440\n",
      "7 448\n",
      "7 456\n",
      "7 464\n",
      "7 472\n",
      "7 480\n",
      "7 488\n",
      "7 496\n",
      "7 504\n",
      "7 512\n",
      "7 520\n",
      "7 528\n",
      "7 536\n",
      "7 544\n",
      "7 552\n",
      "7 560\n",
      "7 568\n",
      "7 576\n",
      "7 584\n",
      "7 592\n",
      "7 600\n",
      "7 608\n",
      "7 616\n",
      "7 624\n",
      "7 632\n",
      "7 640\n",
      "7 648\n",
      "avg: 3.90626\n",
      "8 0\n",
      "8 8\n",
      "8 16\n",
      "8 24\n",
      "8 32\n",
      "8 40\n",
      "8 48\n",
      "8 56\n",
      "8 64\n",
      "8 72\n",
      "8 80\n",
      "8 88\n",
      "8 96\n",
      "8 104\n",
      "8 112\n",
      "8 120\n",
      "8 128\n",
      "8 136\n",
      "8 144\n",
      "8 152\n",
      "8 160\n",
      "8 168\n",
      "8 176\n",
      "8 184\n",
      "8 192\n",
      "8 200\n",
      "8 208\n",
      "8 216\n",
      "8 224\n",
      "8 232\n",
      "8 240\n",
      "8 248\n",
      "8 256\n",
      "8 264\n",
      "8 272\n",
      "8 280\n",
      "8 288\n",
      "8 296\n",
      "8 304\n",
      "8 312\n",
      "8 320\n",
      "8 328\n",
      "8 336\n",
      "8 344\n",
      "8 352\n",
      "8 360\n",
      "8 368\n",
      "8 376\n",
      "8 384\n",
      "8 392\n",
      "8 400\n",
      "8 408\n",
      "8 416\n",
      "8 424\n",
      "8 432\n",
      "8 440\n",
      "8 448\n",
      "8 456\n",
      "8 464\n",
      "8 472\n",
      "8 480\n",
      "8 488\n",
      "8 496\n",
      "8 504\n",
      "8 512\n",
      "8 520\n",
      "8 528\n",
      "8 536\n",
      "8 544\n",
      "8 552\n",
      "8 560\n",
      "8 568\n",
      "8 576\n",
      "8 584\n",
      "8 592\n",
      "8 600\n",
      "8 608\n",
      "8 616\n",
      "8 624\n",
      "8 632\n",
      "8 640\n",
      "8 648\n",
      "avg: 2.24557\n",
      "9 0\n",
      "9 8\n",
      "9 16\n",
      "9 24\n",
      "9 32\n",
      "9 40\n",
      "9 48\n",
      "9 56\n",
      "9 64\n",
      "9 72\n",
      "9 80\n",
      "9 88\n",
      "9 96\n",
      "9 104\n",
      "9 112\n",
      "9 120\n",
      "9 128\n",
      "9 136\n",
      "9 144\n",
      "9 152\n",
      "9 160\n",
      "9 168\n",
      "9 176\n",
      "9 184\n",
      "9 192\n",
      "9 200\n",
      "9 208\n",
      "9 216\n",
      "9 224\n",
      "9 232\n",
      "9 240\n",
      "9 248\n",
      "9 256\n",
      "9 264\n",
      "9 272\n",
      "9 280\n",
      "9 288\n",
      "9 296\n",
      "9 304\n",
      "9 312\n",
      "9 320\n",
      "9 328\n",
      "9 336\n",
      "9 344\n",
      "9 352\n",
      "9 360\n",
      "9 368\n",
      "9 376\n",
      "9 384\n",
      "9 392\n",
      "9 400\n",
      "9 408\n",
      "9 416\n",
      "9 424\n",
      "9 432\n",
      "9 440\n",
      "9 448\n",
      "9 456\n",
      "9 464\n",
      "9 472\n",
      "9 480\n",
      "9 488\n",
      "9 496\n",
      "9 504\n",
      "9 512\n",
      "9 520\n",
      "9 528\n",
      "9 536\n",
      "9 544\n",
      "9 552\n",
      "9 560\n",
      "9 568\n",
      "9 576\n",
      "9 584\n",
      "9 592\n",
      "9 600\n",
      "9 608\n",
      "9 616\n",
      "9 624\n",
      "9 632\n",
      "9 640\n",
      "9 648\n",
      "avg: 2.33589\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.3358891"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAINING_STEPS = 10\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for step in range(TRAINING_STEPS):\n",
    "    for i in range(0, source.num_training - BATCH_SIZE, BATCH_SIZE):\n",
    "        print(step, i)\n",
    "        events = source.training()[\"events\"][i:(i+BATCH_SIZE),:,...,:]\n",
    "        labels = source.training()[\"labels\"][i:(i+BATCH_SIZE),:]\n",
    "        sess.run(train_optimizer, feed_dict={input_tensor: events,\n",
    "                                             y: labels,\n",
    "                                             dropout_keep_prob: 0.5})\n",
    "\n",
    "    events_test = source.testing()[\"events\"]\n",
    "    labels_test = source.testing()[\"labels\"]\n",
    "    avg = sess.run(avg_loss, feed_dict={input_tensor: events_test,\n",
    "                                        y: labels_test,\n",
    "                                        dropout_keep_prob: 1.0})\n",
    "    print(\"avg:\", avg)\n",
    "avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.18716693 -0.14502968 -0.1650719 ]] [-0.12893723 -0.17657488 -0.23264527]\n",
      "[[-0.14262208 -0.16349858 -0.12043285]] [-0.11396603 -0.18117745 -0.21677621]\n",
      "[[-0.04544632 -0.11530989 -0.11746905]] [-0.1094861  -0.17524899 -0.21626075]\n",
      "[[-0.03075144 -0.09589148 -0.13925767]] [-0.10909313 -0.15662379 -0.18436755]\n",
      "[[-0.03155366 -0.10638125 -0.09571987]] [-0.10863434 -0.15778517 -0.16973676]\n",
      "[[ 0.00344877 -0.07023229 -0.01811689]] [-0.12592036 -0.16390473 -0.16941369]\n",
      "[[-0.03829715 -0.1265775  -0.137952  ]] [-0.13915086 -0.16850698 -0.16569153]\n",
      "[[-0.13012195 -0.17130461 -0.09890939]] [-0.14786366 -0.18020282 -0.14778977]\n",
      "[[-0.05588983 -0.09440403 -0.05762909]] [-0.16123768 -0.18644556 -0.13090448]\n",
      "[[-0.06689512 -0.16188392 -0.07853331]] [-0.19940725 -0.23147917 -0.10130116]\n"
     ]
    }
   ],
   "source": [
    "for i in range(100, 110):\n",
    "    predicted = sess.run(out, feed_dict={input_tensor: events_test[i:i+1,:,...,:],\n",
    "                              dropout_keep_prob: 1.0})\n",
    "    expected = labels_test[i,:] * LABEL_SCALE_FACTOR\n",
    "    print(predicted, expected)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
