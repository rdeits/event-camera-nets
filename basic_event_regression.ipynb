{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from eventcnn.datasources.davis import DavisDataset\n",
    "from eventcnn.datasources.eventsource import EventSource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset1 = DavisDataset.named_dataset(\"poster_translation\")\n",
    "dataset2 = DavisDataset.named_dataset(\"shapes_translation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "source1 = EventSource(dataset1, \n",
    "                      testing_fraction=0.2,\n",
    "                      validation_fraction=0.4,\n",
    "                      events_per_block=1000)\n",
    "source2 = EventSource(dataset2, \n",
    "                      testing_fraction=0.2,\n",
    "                      validation_fraction=0.4,\n",
    "                      events_per_block=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined = source1 + source2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_EVENT_SLICES = 5\n",
    "EVENT_PIXEL_SCALING = 2\n",
    "BATCH_SIZE = 60\n",
    "N_EVENT_ROWS = 180 // EVENT_PIXEL_SCALING\n",
    "N_EVENT_COLS = 240 // EVENT_PIXEL_SCALING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Copied from the tensorflow tutorial in class\n",
    "def init_weights(shape):\n",
    "    return tf.Variable(tf.random_normal(shape, stddev=0.01))\n",
    "\n",
    "def init_bias(shape):\n",
    "    return tf.Variable(tf.zeros(shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def training_batch(training, batch_size):\n",
    "    iterator = iter(training)\n",
    "    blocks = [next(iterator) for i in range(batch_size)]\n",
    "    data = np.stack([block.events_rescaled(n_layers=N_EVENT_SLICES,\n",
    "                                         scaling=EVENT_PIXEL_SCALING) for block in blocks])\n",
    "    labels = np.stack([block.delta_position for block in blocks])\n",
    "    return data, labels\n",
    "    \n",
    "def test_data(source):\n",
    "    data = np.stack([block.events_rescaled(n_layers=N_EVENT_SLICES,\n",
    "                                         scaling=EVENT_PIXEL_SCALING) for block in source.testing()])\n",
    "    labels = np.stack([block.delta_position for block in source.testing()])\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def n_output_channels(layer):\n",
    "    return layer.get_shape()[-1].value\n",
    "\n",
    "def n_outputs(layer):\n",
    "    out = layer.get_shape()[1].value\n",
    "    for d in layer.get_shape()[2:]:\n",
    "        out *= d.value\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_tensor = tf.placeholder(tf.float32, [None, N_EVENT_COLS, N_EVENT_ROWS, N_EVENT_SLICES, 1])\n",
    "dropout_keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "conv1 = tf.nn.conv3d(input_tensor, init_weights([3,3,3,1,14]), strides=[1,1,1,1,1], padding='SAME')\n",
    "conv1 = tf.nn.relu(tf.nn.bias_add(conv1, init_bias(n_output_channels(conv1))))\n",
    "pool1 = tf.nn.max_pool3d(conv1, ksize=[1, 2, 2, 2, 1], strides=[1, 2, 2, 2, 1], padding=\"SAME\")\n",
    "\n",
    "conv2 = tf.nn.conv3d(pool1, \n",
    "                     init_weights([3,3,3,output_channels(pool1),14]), \n",
    "                     strides=[1, 1, 1, 1, 1], padding=\"SAME\")\n",
    "conv2 = tf.nn.relu(tf.nn.bias_add(conv2, init_bias(n_output_channels(conv2))))\n",
    "pool2 = tf.nn.max_pool3d(conv1, ksize=[1, 2, 2, 2, 1], strides=[1, 2, 2, 2, 1], padding=\"SAME\")\n",
    "\n",
    "fc3 = tf.reshape(pool2, [-1, n_outputs(pool2)])\n",
    "fc3 = tf.add(tf.matmul(fc3, init_weights([n_outputs(pool2), 32])), init_bias(32))\n",
    "fc3 = tf.nn.relu(fc3)\n",
    "fc3 = tf.nn.dropout(fc3, dropout_keep_prob)\n",
    "\n",
    "out = tf.add(tf.matmul(fc3, init_weights([n_outputs(fc3), 3])), init_bias(3))\n",
    "\n",
    "y = tf.placeholder(tf.float32, [None, 3])\n",
    "\n",
    "loss = tf.nn.l2_loss(tf.sub(out, y))\n",
    "avg_loss = tf.reduce_mean(loss)\n",
    "train_optimizer = tf.train.AdamOptimizer(learning_rate=0.001).minimize(loss)\n",
    "\n",
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-187-8cf2b4c4291a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m         sess.run(train_optimizer, feed_dict={input_tensor: data_batch,\n\u001b[0;32m     11\u001b[0m                                              \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlabels_batch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m                                              dropout_keep_prob: 0.5})\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mdata_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    715\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    716\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 717\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    718\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    719\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    913\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 915\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    916\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    963\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    964\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m--> 965\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m    966\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    967\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m    970\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    971\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 972\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    973\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    974\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m    952\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m    953\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 954\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m    955\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    956\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "TRAINING_STEPS = 10\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for step in range(TRAINING_STEPS):\n",
    "    training_data = combined.training()  # reset the generator\n",
    "    for i in range(combined.num_training // BATCH_SIZE):\n",
    "        data_batch, labels_batch = training_batch(training_data, BATCH_SIZE)\n",
    "        sess.run(train_optimizer, feed_dict={input_tensor: data_batch,\n",
    "                                             y: labels_batch,\n",
    "                                             dropout_keep_prob: 0.5})\n",
    "\n",
    "data_test, labels_test = test_set()\n",
    "avg = sess.run(avg_loss, feed_dict={input_tensor: data_test,\n",
    "                                    y: labels_test,\n",
    "                                    dropout_keep_prob: 1.0})\n",
    "avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
